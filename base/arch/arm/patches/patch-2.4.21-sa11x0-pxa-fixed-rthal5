diff -urNp linux-2.4.21-rmk1-pxa1/Makefile linux-2.4.21-rmk1-pxa1-rthal5/Makefile
--- linux-2.4.21-rmk1-pxa1/Makefile	Thu Dec  4 17:15:16 2003
+++ linux-2.4.21-rmk1-pxa1-rthal5/Makefile	Thu Dec  4 17:17:08 2003
@@ -1,7 +1,7 @@
 VERSION = 2
 PATCHLEVEL = 4
 SUBLEVEL = 21
-EXTRAVERSION =-rmk1-pxa1
+EXTRAVERSION =-rmk1-pxa1-rthal5
 
 KERNELRELEASE=$(VERSION).$(PATCHLEVEL).$(SUBLEVEL)$(EXTRAVERSION)
 
diff -urNp linux-2.4.21-rmk1-pxa1/arch/arm/config.in linux-2.4.21-rmk1-pxa1-rthal5/arch/arm/config.in
--- linux-2.4.21-rmk1-pxa1/arch/arm/config.in	Thu Dec  4 17:15:16 2003
+++ linux-2.4.21-rmk1-pxa1-rthal5/arch/arm/config.in	Thu Dec  4 17:17:08 2003
@@ -520,6 +520,7 @@ if [ "$CONFIG_ARCH_SA1100" = "y" -o \
 fi
 
 source drivers/pci/Config.in
+bool 'RTAI Realtime Hardware abstraction Layer' CONFIG_RTHAL
 bool 'Support for hot-pluggable devices' CONFIG_HOTPLUG
 if [ "$CONFIG_HOTPLUG" = "y" ]; then
    source drivers/pcmcia/Config.in
diff -urNp linux-2.4.21-rmk1-pxa1/arch/arm/defconfig linux-2.4.21-rmk1-pxa1-rthal5/arch/arm/defconfig
--- linux-2.4.21-rmk1-pxa1/arch/arm/defconfig	Mon Nov  5 09:04:53 2001
+++ linux-2.4.21-rmk1-pxa1-rthal5/arch/arm/defconfig	Thu Dec  4 17:17:08 2003
@@ -74,6 +74,7 @@ CONFIG_PCI=y
 # CONFIG_ISA is not set
 # CONFIG_ISA_DMA is not set
 CONFIG_PCI_NAMES=y
+# CONFIG_RTHAL is not set
 # CONFIG_HOTPLUG is not set
 # CONFIG_PCMCIA is not set
 CONFIG_NET=y
diff -urNp linux-2.4.21-rmk1-pxa1/arch/arm/kernel/armksyms.c linux-2.4.21-rmk1-pxa1-rthal5/arch/arm/kernel/armksyms.c
--- linux-2.4.21-rmk1-pxa1/arch/arm/kernel/armksyms.c	Tue Oct  7 19:13:15 2003
+++ linux-2.4.21-rmk1-pxa1-rthal5/arch/arm/kernel/armksyms.c	Thu Dec  4 17:17:08 2003
@@ -20,6 +20,10 @@
 #include <linux/interrupt.h>
 #include <linux/pm.h>
 #include <linux/vt_kern.h>
+#ifdef CONFIG_RTHAL
+#include <linux/console.h>
+#include <linux/sched.h>
+#endif
 
 #include <asm/byteorder.h>
 #include <asm/elf.h>
@@ -105,6 +109,10 @@ EXPORT_SYMBOL(kd_mksound);
 
 EXPORT_SYMBOL_NOVERS(__do_softirq);
 
+#ifdef CONFIG_RTHAL
+EXPORT_SYMBOL(console_drivers);
+#endif
+
 	/* platform dependent support */
 EXPORT_SYMBOL(dump_thread);
 EXPORT_SYMBOL(dump_fpu);
@@ -254,10 +262,13 @@ EXPORT_SYMBOL(elf_platform);
 EXPORT_SYMBOL(elf_hwcap);
 
 	/* syscalls */
+#ifndef CONFIG_RTHAL
+/* exported elsewhere when CONFIG_RTHAL is on */
 EXPORT_SYMBOL(sys_write);
 EXPORT_SYMBOL(sys_read);
-EXPORT_SYMBOL(sys_lseek);
 EXPORT_SYMBOL(sys_open);
+#endif
+EXPORT_SYMBOL(sys_lseek);
 EXPORT_SYMBOL(sys_exit);
 EXPORT_SYMBOL(sys_wait4);
 
@@ -268,3 +279,11 @@ EXPORT_SYMBOL_NOVERS(__down_trylock_fail
 EXPORT_SYMBOL_NOVERS(__up_wakeup);
 
 EXPORT_SYMBOL(get_wchan);
+
+	/* RTAI */
+#ifdef CONFIG_RTHAL
+extern struct irqdesc irq_desc[NR_IRQS];
+EXPORT_SYMBOL(rthal);
+EXPORT_SYMBOL(irq_desc); 
+EXPORT_SYMBOL(do_timer);
+#endif
diff -urNp linux-2.4.21-rmk1-pxa1/arch/arm/kernel/entry-armv.S linux-2.4.21-rmk1-pxa1-rthal5/arch/arm/kernel/entry-armv.S
--- linux-2.4.21-rmk1-pxa1/arch/arm/kernel/entry-armv.S	Thu Dec  4 17:15:16 2003
+++ linux-2.4.21-rmk1-pxa1-rthal5/arch/arm/kernel/entry-armv.S	Thu Dec  4 17:17:08 2003
@@ -380,6 +380,11 @@ ENTRY(soft_irq_mask)
 		ands	\irqstat, \irqstat, \irqnr
 		mov	\irqnr, #0
 		beq	1001f
+#ifdef CONFIG_RTHAL
+		tst	\irqstat, #0x04000000	@ check OSMR0 first
+		movne	\irqnr, #26
+		bne	1001f
+#endif
 		tst	\irqstat, #0xff
 		moveq	\irqstat, \irqstat, lsr #8
 		addeq	\irqnr, \irqnr, #8
@@ -712,9 +717,8 @@ __dabt_svc:	sub	sp, sp, #S_FRAME_SIZE
 		msr	cpsr_c, r9
 		mov	r2, sp
 		bl	SYMBOL_NAME(do_DataAbort)
-		mov	r0, #I_BIT | MODE_SVC
-		msr	cpsr_c, r0
-		ldr	r0, [sp, #S_PSR]
+		disable_irq r0				@ Yes, this disables interrupts - for
+		ldr	r0, [sp, #S_PSR]		@ the next 2 instructions. Safe.
 		msr	spsr, r0
 		ldmia	sp, {r0 - pc}^			@ load r0 - pc, cpsr
 
@@ -733,7 +737,12 @@ __irq_svc:	sub	sp, sp, #S_FRAME_SIZE
 		@ routine called with r0 = irq number, r1 = struct pt_regs *
 		@
 		adrsvc	ne, lr, 1b
+#ifndef CONFIG_RTHAL
 		bne	asm_do_IRQ
+#else
+		ldrne	r7, .rthal			@ load pointer rthal
+		ldrne	pc, [r7, #0]			@ branch to rthal.do_IRQ (1st in RTHAL)
+#endif
 		ldr	r0, [sp, #S_PSR]		@ irqs are already disabled
 		msr	spsr, r0
 		ldmia	sp, {r0 - pc}^			@ load r0 - pc, cpsr
@@ -750,6 +759,19 @@ __und_svc:	sub	sp, sp, #S_FRAME_SIZE
 		add	r4, sp, #S_SP
 		stmia	r4, {r5 - r9}			@ save sp_SVC, lr_SVC, pc, cpsr, old_ro
 
+#ifdef CONFIG_RTHAL
+		ldr	r7, .rthal			@ load pointer rthal
+		ldr	r7, [r7, #8]			@ load pointer rthal.do_TRAP (3rd in RTHAL)
+		cmp	r7, #0
+		beq	2f
+		mov	r0, #4				@ SIGILL
+		mov	r1, sp				@ struct pt_regs *regs
+		mov	lr, pc
+		mov	pc, r7				@ check, if this is a relevant code
+		cmp	r0, #0				@ check return value
+		beq	1f				@ else let linux do what it has to do
+2:		
+#endif
 		adrsvc	al, r9, 1f			@ r9  = normal FP return
 		bl	call_fpe			@ lr  = undefined instr return
 
@@ -757,8 +779,7 @@ __und_svc:	sub	sp, sp, #S_FRAME_SIZE
 		mov	r1, sp				@ struct pt_regs *regs
 		bl	SYMBOL_NAME(do_undefinstr)
 
-1:		mov	r0, #I_BIT | MODE_SVC
-		msr	cpsr_c, r0
+1:		disable_irq r0
 		ldr	lr, [sp, #S_PSR]		@ Get SVC cpsr
 		msr	spsr, lr
 		ldmia	sp, {r0 - pc}^			@ Restore SVC registers
@@ -779,8 +800,7 @@ __pabt_svc:	sub	sp, sp, #S_FRAME_SIZE
 		mov	r0, r2				@ address (pc)
 		mov	r1, sp				@ regs
 		bl	SYMBOL_NAME(do_PrefetchAbort)	@ call abort handler
-		mov	r0, #I_BIT | MODE_SVC
-		msr	cpsr_c, r0
+		disable_irq r0
 		ldr	r0, [sp, #S_PSR]
 		msr	spsr, r0
 		ldmia	sp, {r0 - pc}^			@ load r0 - pc, cpsr
@@ -792,6 +812,9 @@ __pabt_svc:	sub	sp, sp, #S_FRAME_SIZE
 #ifdef MULTI_CPU
 .LCprocfns:	.word	SYMBOL_NAME(processor)
 #endif
+#ifdef CONFIG_RTHAL
+.rthal:		.word	SYMBOL_NAME(rthal)
+#endif
 .LCfp:		.word	SYMBOL_NAME(fp_enter)
 
 		irq_prio_table
@@ -817,8 +840,7 @@ __dabt_usr:	sub	sp, sp, #S_FRAME_SIZE		@
 #else
 		bl	cpu_data_abort
 #endif
-		mov	r2, #MODE_SVC
-		msr	cpsr_c, r2			@ Enable interrupts
+		enable_irq r2				@ Enable interrupts
 		mov	r2, sp
 		adrsvc	al, lr, ret_from_exception
 		b	SYMBOL_NAME(do_DataAbort)
@@ -839,7 +861,13 @@ __irq_usr:	sub	sp, sp, #S_FRAME_SIZE
 		@
 		@ routine called with r0 = irq number, r1 = struct pt_regs *
 		@
+#ifndef CONFIG_RTHAL
 		bne	asm_do_IRQ
+#else
+		ldrne	r7, .rthal			@ load pointer rthal
+		ldrne	pc, [r7, #0]			@ branch to rthal.do_IRQ (1st in RTHAL)
+		disable_irq r7				@ we do not disable IRQs in dispatch_irq - do it here
+#endif
 		mov	why, #0
 		get_current_task tsk
 		b	ret_to_user
@@ -861,15 +889,15 @@ __und_usr:	sub	sp, sp, #S_FRAME_SIZE		@ 
 		adrsvc	al, r9, ret_from_exception	@ r9  = normal FP return
 		adrsvc	al, lr, fpundefinstr		@ lr  = undefined instr return
 
-call_fpe:	get_current_task r10
+call_fpe:	enable_irq r10
+		get_current_task r10
 		mov	r8, #1
 		strb	r8, [r10, #TSK_USED_MATH]	@ set current->used_math
 		ldr	r4, .LCfp
 		add	r10, r10, #TSS_FPESAVE		@ r10 = workspace
 		ldr	pc, [r4]			@ Call FP module USR entry point
 
-fpundefinstr:	mov	r0, #MODE_SVC
-		msr	cpsr_c, r0			@ Enable interrupts
+fpundefinstr:	enable_irq r0				@ Enable interrupts
 		mov	r0, lr
 		mov	r1, sp
 		adrsvc	al, lr, ret_from_exception
@@ -885,8 +913,7 @@ __pabt_usr:	sub	sp, sp, #S_FRAME_SIZE		@
 		stmdb	r8, {sp, lr}^			@ Save sp_usr lr_usr
 		alignment_trap r4, r7, __temp_abt
 		zero_fp
-		mov	r0, #MODE_SVC
-		msr	cpsr_c, r0			@ Enable interrupts
+		enable_irq r0				@ Enable interrupts
 		mov	r0, r5				@ address (pc)
 		mov	r1, sp				@ regs
 		bl	SYMBOL_NAME(do_PrefetchAbort)	@ call abort handler
diff -urNp linux-2.4.21-rmk1-pxa1/arch/arm/kernel/entry-common.S linux-2.4.21-rmk1-pxa1-rthal5/arch/arm/kernel/entry-common.S
--- linux-2.4.21-rmk1-pxa1/arch/arm/kernel/entry-common.S	Tue Oct  7 19:13:15 2003
+++ linux-2.4.21-rmk1-pxa1-rthal5/arch/arm/kernel/entry-common.S	Thu Dec  4 17:17:08 2003
@@ -53,7 +53,11 @@ slow:	str	r0, [sp, #S_R0+S_OFF]!	@ retur
  * "slow" syscall return path.  "why" tells us if this was a real syscall.
  */
 reschedule:
+#ifndef CONFIG_RTHAL
 	bl	SYMBOL_NAME(schedule)
+#else
+	bl	SYMBOL_NAME(rt_wrap_schedule)
+#endif
 ret_disable_irq:
 	disable_irq r1				@ ensure IRQs are disabled
 ENTRY(ret_to_user)
@@ -72,7 +76,11 @@ __do_signal:
 	mov	r0, #0				@ NULL 'oldset'
 	mov	r1, sp				@ 'regs'
 	mov	r2, why				@ 'syscall'
+#ifndef CONFIG_RTHAL
 	bl	SYMBOL_NAME(do_signal)		@ note the bl above sets lr
+#else
+	bl	SYMBOL_NAME(rt_wrap_do_signal)		@ note the bl above sets lr
+#endif
 	disable_irq r1				@ ensure IRQs are disabled
 	b	restore
 
@@ -90,7 +98,11 @@ ENTRY(ret_from_fork)
 	beq	ret_disable_irq
 	mov	r1, sp
 	mov	r0, #1				@ trace exit [IP = 1]
+#ifndef CONFIG_RTHAL
 	bl	SYMBOL_NAME(syscall_trace)
+#else
+	bl	SYMBOL_NAME(rt_wrap_syscall_trace)
+#endif
 	b	ret_disable_irq
 	
 
@@ -145,6 +157,11 @@ ENTRY(vector_swi)
 	get_current_task tsk
 	ldr	ip, [tsk, #TSK_PTRACE]		@ check for syscall tracing
 	bic	scno, scno, #0xff000000		@ mask off SWI op-code
+#ifdef CONFIG_RTHAL
+	ldr	tbl, .rtai_magic		@ check for RTAI SRQ
+	cmp	scno, tbl			@ (use tbl for scratch)
+	beq	4f
+#endif
 	eor	scno, scno, #OS_NUMBER << 20	@ check OS number
 	adr	tbl, sys_call_table		@ load syscall table pointer
 	tst	ip, #PT_TRACESYS		@ are we tracing syscalls?
@@ -160,6 +177,20 @@ ENTRY(vector_swi)
 	eor	r0, scno, #OS_NUMBER << 20	@ put OS number back
 	bcs	SYMBOL_NAME(arm_syscall)	
 	b	SYMBOL_NAME(sys_ni_syscall)	@ not private func
+
+#ifdef CONFIG_RTHAL
+4:	ldr	r7, .rthal		@ load pointer to rthal
+	ldr	r7, [r7, #4]		@ load pointer to do_SRQ, [rthal+4]
+	cmp	r7, #0
+	movne	lr, pc                  @ call ...
+	movne	pc, r7			@ ... if available
+	str	r0, [sp, #S_R0 + S_OFF]	@ save returned r0
+	str	r1, [sp, #S_R1 + S_OFF]	@ save returned r1
+	add	sp, sp, #S_OFF		@ hmm, leave anyway
+	b	restore
+.rtai_magic:	.word	0x404404		@ RTAI SRQ MAGIC
+.rthal:		.word	SYMBOL_NAME(rthal)	@ RTHAL
+#endif
 
 	/*
 	 * This is the really slow path.  We're going to be doing
diff -urNp linux-2.4.21-rmk1-pxa1/arch/arm/kernel/irq.c linux-2.4.21-rmk1-pxa1-rthal5/arch/arm/kernel/irq.c
--- linux-2.4.21-rmk1-pxa1/arch/arm/kernel/irq.c	Tue Oct  7 19:13:15 2003
+++ linux-2.4.21-rmk1-pxa1-rthal5/arch/arm/kernel/irq.c	Thu Dec  4 17:17:08 2003
@@ -686,3 +686,189 @@ void __init init_IRQ(void)
 	init_arch_irq();
 	init_dma();
 }
+
+#ifdef CONFIG_RTHAL
+/*
+ * RTAI
+ * This is the most appropriate place to setup rthal.
+ */
+static void linux_cli(void)
+{
+	hard_local_irq_disable();
+}
+
+static void linux_sti(void)
+{
+	hard_local_irq_enable();
+}
+
+static unsigned int linux_save_flags(void)
+{
+	int flags;
+	hard_local_save_flags(flags);
+	return flags;
+}
+
+static unsigned int linux_save_flags_cli(void)
+{
+	int flags;
+	hard_local_irq_save(flags);
+	return flags;
+}
+
+static unsigned int linux_save_flags_sti(void)
+{
+	int flags;
+	hard_local_irq_set(flags);
+	return flags;
+}
+
+static void linux_restore_flags(unsigned int flags)
+{
+	hard_local_irq_restore(flags);
+}
+
+static void linux_fcli(void)
+{
+	hard_clf();
+}
+
+static void linux_fsti(void)
+{
+	hard_stf();
+}
+
+volatile struct rt_hal rthal = {
+	.do_IRQ			= asm_do_IRQ,	/* irq-dispatcher */
+	.do_SRQ			= NULL,		/* srq-dispatcher */
+	.do_TRAP		= NULL,		/* trap-handler */
+	.disint			= linux_cli,
+	.enint			= linux_sti,
+	.getflags		= linux_save_flags,
+	.setflags		= linux_restore_flags,
+	.getflags_and_cli	= linux_save_flags_cli,
+	.fdisint		= linux_fcli,
+	.fenint			= linux_fsti,
+	.copy_back		= NULL, /* copy linux-flags back, don't deliver pending interrupts */
+	.c_do_IRQ		= do_IRQ,
+	.getflags_and_sti	= linux_save_flags_sti,
+};
+
+/* Wrappers for entry-common.S
+ * Assumption: the only exceptions, allowed in rt-context,
+ * are interrupts and traps (e.g. floating point emulation),
+ * which are processed accordingly. All the rest can happen
+ * only in Linux. Which means, that interrupts before the
+ * exception were hard-enabled, the state of soft I-bit is
+ * unknown.
+ * Concept - all these wrappers are called on the path:
+ * - exception
+ *   (possibly, enable interrupts)
+ * - call a Linux C-function, which might schedule, sleep,
+ *   change interrupt-status
+ * - return to asm
+ *   (possibly, change interupt status)
+ * - switch back to where exception occured
+ * So, the wrappers do:
+ * - modify Linux I-bit according to the current hard I-bit
+ * - hard enable interrupts
+ * - call the wrapped function
+ * - save the current Linux I-bit to the hard I-bit
+ * - restore Linux I-bit state from before-wrapping
+ *   (emulate return from exception)
+ */
+
+extern asmlinkage int do_signal(sigset_t *oldset, struct pt_regs *regs, int syscall);
+extern asmlinkage void syscall_trace(int why, struct pt_regs *regs);
+asmlinkage void rt_wrap_schedule(void)
+{
+	unsigned long flags;
+	unsigned long i_bit = 0, linux_i_bit = 0;
+
+	if (rthal.do_IRQ != asm_do_IRQ) {
+		hard_save_flags(flags);
+		i_bit = flags & I_BIT;
+		linux_i_bit = rthal.getflags() & I_BIT;
+		if (i_bit) {
+			if (! linux_i_bit)
+				rthal.disint();
+			hard_sti();
+		} else if (linux_i_bit)
+			rthal.enint();
+	}
+	schedule();
+	if (rthal.do_IRQ != asm_do_IRQ) {
+		hard_save_flags(flags);
+		if (flags & I_BIT) {
+			hard_sti();
+			BUG();
+		}
+
+		if (rthal.getflags() & I_BIT)
+			hard_cli();
+		rthal.copy_back(linux_i_bit, 0);
+	}
+}
+
+asmlinkage void rt_wrap_syscall_trace(int why, struct pt_regs *regs)
+{
+	unsigned long flags;
+	unsigned long i_bit = 0, linux_i_bit = 0;
+
+	if (rthal.do_IRQ != asm_do_IRQ) {
+		hard_save_flags(flags);
+		i_bit = flags & I_BIT;
+		linux_i_bit = rthal.getflags() & I_BIT;
+		if (i_bit) {
+			if (! linux_i_bit)
+				rthal.disint();
+			hard_sti();
+		} else if (linux_i_bit)
+			rthal.enint();
+	}
+	syscall_trace(why, regs);
+	if (rthal.do_IRQ != asm_do_IRQ) {
+		hard_save_flags(flags);
+		if (flags & I_BIT) {
+			hard_sti();
+			BUG();
+		}
+
+		if (rthal.getflags() & I_BIT)
+			hard_cli();
+		rthal.copy_back(linux_i_bit, 0);
+	}
+}
+
+asmlinkage int rt_wrap_do_signal(sigset_t *oldset, struct pt_regs *regs, int syscall)
+{
+	unsigned long flags;
+	unsigned long i_bit = 0, linux_i_bit = 0;
+	int ret;
+
+	if (rthal.do_IRQ != asm_do_IRQ) {
+		hard_save_flags(flags);
+		i_bit = flags & I_BIT;
+		linux_i_bit = rthal.getflags() & I_BIT;
+		if (i_bit) {
+			if (! linux_i_bit)
+				rthal.disint();
+			hard_sti();
+		} else if (linux_i_bit)
+			rthal.enint();
+	}
+	ret = do_signal(oldset, regs, syscall);
+	if (rthal.do_IRQ != asm_do_IRQ) {
+		hard_save_flags(flags);
+		if (flags & I_BIT) {
+			hard_sti();
+			BUG();
+		}
+
+		if (rthal.getflags() & I_BIT)
+			hard_cli();
+		rthal.copy_back(linux_i_bit, 0);
+	}
+	return ret;
+}
+#endif
diff -urNp linux-2.4.21-rmk1-pxa1/arch/arm/mach-pxa/generic.c linux-2.4.21-rmk1-pxa1-rthal5/arch/arm/mach-pxa/generic.c
--- linux-2.4.21-rmk1-pxa1/arch/arm/mach-pxa/generic.c	Thu Dec  4 17:15:16 2003
+++ linux-2.4.21-rmk1-pxa1-rthal5/arch/arm/mach-pxa/generic.c	Thu Dec  4 17:17:08 2003
@@ -108,14 +108,22 @@ void set_GPIO_mode(int gpio_mode)
 	int fn = (gpio_mode & GPIO_MD_MASK_FN) >> 8;
 	int gafr;
 
+#ifndef CONFIG_RTHAL
 	local_irq_save(flags);
+#else
+	hard_local_irq_save(flags);
+#endif
 	if (gpio_mode & GPIO_MD_MASK_DIR)
 		GPDR(gpio) |= GPIO_bit(gpio);
 	else
 		GPDR(gpio) &= ~GPIO_bit(gpio);
 	gafr = GAFR(gpio) & ~(0x3 << (((gpio) & 0xf)*2));
 	GAFR(gpio) = gafr |  (fn  << (((gpio) & 0xf)*2));
+#ifndef CONFIG_RTHAL
 	local_irq_restore(flags);
+#else
+	hard_local_irq_restore(flags);
+#endif
 }
 
 EXPORT_SYMBOL(set_GPIO_mode);
diff -urNp linux-2.4.21-rmk1-pxa1/arch/arm/mach-pxa/irq.c linux-2.4.21-rmk1-pxa1-rthal5/arch/arm/mach-pxa/irq.c
--- linux-2.4.21-rmk1-pxa1/arch/arm/mach-pxa/irq.c	Thu Dec  4 17:15:16 2003
+++ linux-2.4.21-rmk1-pxa1-rthal5/arch/arm/mach-pxa/irq.c	Thu Dec  4 17:17:08 2003
@@ -64,11 +64,13 @@ EXPORT_SYMBOL(set_GPIO_IRQ_edge);
 static void pxa_mask_irq(unsigned int irq)
 {
 	ICMR &= ~(1 << (irq + PXA_IRQ_SKIP));
+	irq_desc[irq].masked = 1;
 }
 
 static void pxa_unmask_irq(unsigned int irq)
 {
 	ICMR |= (1 << (irq + PXA_IRQ_SKIP));
+	irq_desc[irq].masked = 0;
 }
 
 /*
@@ -79,11 +81,13 @@ static void pxa_mask_and_ack_GPIO_0_1_ir
 {
 	ICMR &= ~(1 << (irq + PXA_IRQ_SKIP));
 	GEDR0 = (1 << (irq - IRQ_GPIO0));
+	irq_desc[irq].masked = 1;
 }
 
 static void pxa_mask_GPIO_0_1_irq(unsigned int irq)
 {
 	ICMR &= ~(1 << (irq + PXA_IRQ_SKIP));
+	irq_desc[irq].masked = 1;
 }
 
 static void pxa_unmask_GPIO_0_1_irq(unsigned int irq)
@@ -92,6 +96,7 @@ static void pxa_unmask_GPIO_0_1_irq(unsi
 	GRER0 = (GRER0 & ~(1 << gpio))|(GPIO_IRQ_rising_edge[0] & (1 << gpio));
 	GFER0 = (GFER0 & ~(1 << gpio))|(GPIO_IRQ_falling_edge[0] & (1 << gpio));
 	ICMR |= (1 << (irq + PXA_IRQ_SKIP));
+	irq_desc[irq].masked = 0;
 }
 
 /*
@@ -101,8 +106,10 @@ static void pxa_unmask_GPIO_0_1_irq(unsi
 static int GPIO_2_80_enabled[3];	/* enabled i.e. unmasked GPIO IRQs */
 static int GPIO_2_80_spurious[3];	/* GPIOs that triggered when masked */
 
-static void pxa_GPIO_2_80_demux(int irq, void *dev_id,
-				    struct pt_regs *regs)
+#ifndef CONFIG_RTHAL
+static
+#endif
+void pxa_GPIO_2_80_demux(int irq, void *dev_id, struct pt_regs *regs)
 {
 	int i, gedr, spurious;
 
@@ -127,8 +134,15 @@ static void pxa_GPIO_2_80_demux(int irq,
 		}
 
 		for (i = 2; i < 32; ++i) {
+#ifndef CONFIG_RTHAL
 			if (gedr & (1<<i)) {
 				do_IRQ (IRQ_GPIO(2) + i - 2, regs);
+#else
+			if ((gedr = (GEDR0 & ~3)) & (1<<i)) {
+				pxa_unmask_irq(IRQ_GPIO_2_80);
+				rthal.c_do_IRQ(IRQ_GPIO(2) + i - 2, regs);
+				break;
+#endif
 			}
 		}
 	}
@@ -144,8 +158,15 @@ static void pxa_GPIO_2_80_demux(int irq,
 		}
 
 		for (i = 0; i < 32; ++i) {
+#ifndef CONFIG_RTHAL
 			if (gedr & (1<<i)) {
 				do_IRQ (IRQ_GPIO(32) + i, regs);
+#else
+			if ((gedr = GEDR1) & (1<<i)) {
+				pxa_unmask_irq(IRQ_GPIO_2_80);
+				rthal.c_do_IRQ(IRQ_GPIO(32) + i, regs);
+				break;
+#endif
 			}
 		}
 	}
@@ -161,8 +182,15 @@ static void pxa_GPIO_2_80_demux(int irq,
 		}
 
 		for (i = 0; i < 17; ++i) {
+#ifndef CONFIG_RTHAL
 			if (gedr & (1<<i)) {
 				do_IRQ (IRQ_GPIO(64) + i, regs);
+#else
+			if ((gedr = (GEDR2 & 0x0001ffff)) & (1<<i)) {
+				pxa_unmask_irq(IRQ_GPIO_2_80);
+				rthal.c_do_IRQ(IRQ_GPIO(64) + i, regs);
+				break;
+#endif
 			}
 		}
 	}
@@ -184,9 +212,18 @@ static void pxa_mask_and_ack_GPIO_2_80_i
 	int gpio_nr = IRQ_TO_GPIO_2_80(irq);
 	int mask = 1 << (gpio_nr & 0x1f);
 	int index = gpio_nr >> 5;
+#ifdef CONFIG_RTHAL
+	unsigned long flags;
+
+	hard_save_flags_cli(flags);
+#endif
 	GPIO_2_80_spurious[index] &= ~mask;
 	GPIO_2_80_enabled[index] &= ~mask;
 	GEDR_x(index) = mask;
+	irq_desc[irq].masked = 1;
+#ifdef CONFIG_RTHAL
+	hard_restore_flags(flags);
+#endif
 }
 
 static void pxa_mask_GPIO_2_80_irq(unsigned int irq)
@@ -194,8 +231,17 @@ static void pxa_mask_GPIO_2_80_irq(unsig
 	int gpio_nr = IRQ_TO_GPIO_2_80(irq);
 	int mask = 1 << (gpio_nr & 0x1f);
 	int index = gpio_nr >> 5;
+#ifdef CONFIG_RTHAL
+	unsigned long flags;
+
+	hard_save_flags_cli(flags);
+#endif
 	GPIO_2_80_spurious[index] &= ~mask;
 	GPIO_2_80_enabled[index] &= ~mask;
+	irq_desc[irq].masked = 1;
+#ifdef CONFIG_RTHAL
+	hard_restore_flags(flags);
+#endif
 }
 
 static void pxa_unmask_GPIO_2_80_irq(unsigned int irq)
@@ -203,20 +249,35 @@ static void pxa_unmask_GPIO_2_80_irq(uns
 	int gpio_nr = IRQ_TO_GPIO_2_80(irq);
 	int mask = 1 << (gpio_nr & 0x1f);
 	int index = gpio_nr >> 5;
+#ifdef CONFIG_RTHAL
+	unsigned long flags;
+
+	hard_save_flags_cli(flags);
+#endif
 	if (GPIO_2_80_spurious[index] & mask) {
 		/*
 		 * We don't want to miss an interrupt that would have occurred
 		 * while it was masked.  Simulate it if it is the case.
 		 */
 		int state = GPLR_x(index);
+//		printk(KERN_ERR"Emulating GPIO IRQ %d\n", irq);
 		if (((state & GPIO_IRQ_rising_edge[index]) |
 		     (~state & GPIO_IRQ_falling_edge[index])) & mask)
 		{
 			/* just in case it gets referenced: */
 			struct pt_regs dummy;
 
+#ifdef CONFIG_RTHAL
+			hard_restore_flags(flags);
+#endif
 			memzero(&dummy, sizeof(dummy));
-			do_IRQ(irq, &dummy);
+#ifndef CONFIG_RTHAL
+ 			do_IRQ(irq, &dummy);
+#else
+			hard_cli();
+			rthal.c_do_IRQ(irq, &dummy);
+			hard_restore_flags(flags);
+#endif
 
 			/* we are being called recursively from do_IRQ() */
 			return;
@@ -227,6 +288,10 @@ static void pxa_unmask_GPIO_2_80_irq(uns
 		(GRER_x(index) & ~mask) | (GPIO_IRQ_rising_edge[index] & mask);
 	GFER_x(index) =
 		(GFER_x(index) & ~mask) | (GPIO_IRQ_falling_edge[index] & mask);
+	irq_desc[irq].masked = 0;
+#ifdef CONFIG_RTHAL
+	hard_restore_flags(flags);
+#endif
 }
 
 
@@ -256,6 +321,7 @@ void __init pxa_init_irq(void)
 		irq_desc[irq].mask_ack	= pxa_mask_irq;
 		irq_desc[irq].mask	= pxa_mask_irq;
 		irq_desc[irq].unmask	= pxa_unmask_irq;
+		irq_desc[irq].masked	= 0;
 	}
 
 	/*
@@ -269,6 +335,7 @@ void __init pxa_init_irq(void)
 		irq_desc[irq].mask_ack	= pxa_mask_and_ack_GPIO_0_1_irq;
 		irq_desc[irq].mask	= pxa_mask_GPIO_0_1_irq;
 		irq_desc[irq].unmask	= pxa_unmask_GPIO_0_1_irq;
+		irq_desc[irq].masked	= 0;
 	}
 
 	for (irq = IRQ_GPIO(2); irq <= IRQ_GPIO(80); irq++) {
@@ -277,6 +344,11 @@ void __init pxa_init_irq(void)
 		irq_desc[irq].mask_ack	= pxa_mask_and_ack_GPIO_2_80_irq;
 		irq_desc[irq].mask	= pxa_mask_GPIO_2_80_irq;
 		irq_desc[irq].unmask	= pxa_unmask_GPIO_2_80_irq;
+		irq_desc[irq].masked	= 0;
 	}
 	setup_arm_irq( IRQ_GPIO_2_80, &GPIO_2_80_irqaction );
 }
+
+#ifdef CONFIG_RTHAL
+EXPORT_SYMBOL(pxa_GPIO_2_80_demux);
+#endif
diff -urNp linux-2.4.21-rmk1-pxa1/arch/arm/mach-sa1100/cpu-sa1110.c linux-2.4.21-rmk1-pxa1-rthal5/arch/arm/mach-sa1100/cpu-sa1110.c
--- linux-2.4.21-rmk1-pxa1/arch/arm/mach-sa1100/cpu-sa1110.c	Tue Oct  7 19:13:16 2003
+++ linux-2.4.21-rmk1-pxa1-rthal5/arch/arm/mach-sa1100/cpu-sa1110.c	Thu Dec  4 17:17:08 2003
@@ -234,7 +234,11 @@ static void sa1110_setspeed(unsigned int
 	 * This means that we won't access SDRAM for the duration of
 	 * the programming.
 	 */
+#ifndef CONFIG_RTHAL
 	local_irq_save(flags);
+#else
+	hard_local_irq_save(flags);
+#endif
 	asm("mcr p15, 0, %0, c7, c10, 4" : : "r" (0));
 	udelay(10);
 	__asm__ __volatile__("					\n\
@@ -255,7 +259,11 @@ static void sa1110_setspeed(unsigned int
 		: "r" (&MDCNFG), "r" (&PPCR), "0" (sd.mdcnfg),
 		  "r" (sd.mdrefr), "r" (sd.mdcas[0]),
 		  "r" (sd.mdcas[1]), "r" (sd.mdcas[2]), "r" (ppcr));
+#ifndef CONFIG_RTHAL
 	local_irq_restore(flags);
+#else
+	hard_local_irq_restore(flags);
+#endif
 
 	/*
 	 * Now, return the SDRAM refresh back to normal.
diff -urNp linux-2.4.21-rmk1-pxa1/arch/arm/mach-sa1100/irq.c linux-2.4.21-rmk1-pxa1-rthal5/arch/arm/mach-sa1100/irq.c
--- linux-2.4.21-rmk1-pxa1/arch/arm/mach-sa1100/irq.c	Tue Oct  7 19:13:16 2003
+++ linux-2.4.21-rmk1-pxa1-rthal5/arch/arm/mach-sa1100/irq.c	Thu Dec  4 17:17:09 2003
@@ -34,7 +34,7 @@
  */
 static int GPIO_IRQ_rising_edge;
 static int GPIO_IRQ_falling_edge;
-static int GPIO_IRQ_mask = (1 << 11) - 1;
+static volatile int GPIO_IRQ_mask = (1 << 11) - 1;
 
 void set_GPIO_IRQ_edge(int gpio_mask, int edge)
 {
@@ -53,8 +53,8 @@ void set_GPIO_IRQ_edge(int gpio_mask, in
 		GPIO_IRQ_rising_edge &= ~gpio_mask;
 	GPDR &= ~gpio_mask;
 	GAFR &= ~gpio_mask;
-	GRER = GPIO_IRQ_rising_edge & GPIO_IRQ_mask;
-	GFER = GPIO_IRQ_falling_edge & GPIO_IRQ_mask;
+	GRER |= GPIO_IRQ_rising_edge & gpio_mask;
+	GFER |= GPIO_IRQ_falling_edge & gpio_mask;
 	while (gpio_mask) {
 		if (irq == 11)
 			irq = IRQ_GPIO11;
@@ -77,11 +77,13 @@ EXPORT_SYMBOL(set_GPIO_IRQ_edge);
 static void sa1100_mask_irq(unsigned int irq)
 {
 	ICMR &= ~(1 << irq);
+	irq_desc[irq].masked = 1;
 }
 
 static void sa1100_unmask_irq(unsigned int irq)
 {
 	ICMR |= (1 << irq);
+	irq_desc[irq].masked = 0;
 }
 
 /*
@@ -94,25 +96,31 @@ static void sa1100_mask_and_ack_GPIO0_10
 
 	ICMR &= ~mask;
 	GEDR = mask;
+	irq_desc[irq].masked = 1;
 }
 
 static void sa1100_mask_GPIO0_10_irq(unsigned int irq)
 {
 	ICMR &= ~(1 << irq);
+	irq_desc[irq].masked = 1;
 }
 
 static void sa1100_unmask_GPIO0_10_irq(unsigned int irq)
 {
 	ICMR |= 1 << irq;
+	irq_desc[irq].masked = 0;
 }
 
 /*
  * Install handler for GPIO 11-27 edge detect interrupts
  */
 
-static int GPIO_11_27_spurious;		/* GPIOs that triggered when masked */
+static volatile int GPIO_11_27_spurious;		/* GPIOs that triggered when masked */
 
-static void sa1100_GPIO11_27_demux(int irq, void *dev_id,
+#ifndef CONFIG_RTHAL
+static 
+#endif
+void sa1100_GPIO11_27_demux(int irq, void *dev_id,
 				   struct pt_regs *regs)
 {
 	int i, spurious;
@@ -129,17 +137,25 @@ static void sa1100_GPIO11_27_demux(int i
 		 */
 		spurious = irq & ~GPIO_IRQ_mask;
 		if (spurious) {
+			unsigned long mask = ~(spurious & GPIO_11_27_spurious);
 			GEDR = spurious;
-			GRER &= ~(spurious & GPIO_11_27_spurious);
-			GFER &= ~(spurious & GPIO_11_27_spurious);
+			GRER &= mask;
+			GFER &= mask;
 			GPIO_11_27_spurious |= spurious;
 			irq ^= spurious;
 			if (!irq) continue;
 		}
 
 		for (i = 11; i <= 27; ++i) {
+#ifndef CONFIG_RTHAL
 			if (irq & (1<<i)) {
 				do_IRQ(IRQ_GPIO11 + i - 11, regs);
+#else
+			if ((irq = (GEDR & 0xfffff800)) & (1<<i)) {
+				sa1100_unmask_irq(11);
+				rthal.c_do_IRQ(IRQ_GPIO11 + i - 11, regs);
+				break;
+#endif
 			}
 		}
 	}
@@ -154,21 +170,44 @@ static struct irqaction GPIO11_27_irq = 
 static void sa1100_mask_and_ack_GPIO11_27_irq(unsigned int irq)
 {
 	unsigned int mask = (1 << GPIO_11_27_IRQ(irq));
+#ifdef CONFIG_RTHAL
+	unsigned long flags;
+
+	hard_save_flags_cli(flags);
+#endif
 	GPIO_11_27_spurious &= ~mask;
 	GPIO_IRQ_mask &= ~mask;
 	GEDR = mask;
+	irq_desc[irq].masked = 1;
+#ifdef CONFIG_RTHAL
+	hard_restore_flags(flags);
+#endif
 }
 
 static void sa1100_mask_GPIO11_27_irq(unsigned int irq)
 {
 	unsigned int mask = (1 << GPIO_11_27_IRQ(irq));
+#ifdef CONFIG_RTHAL
+	unsigned long flags;
+
+	hard_save_flags_cli(flags);
+#endif
 	GPIO_11_27_spurious &= ~mask;
 	GPIO_IRQ_mask &= ~mask;
+	irq_desc[irq].masked = 1;
+#ifdef CONFIG_RTHAL
+	hard_restore_flags(flags);
+#endif
 }
 
 static void sa1100_unmask_GPIO11_27_irq(unsigned int irq)
 {
 	unsigned int mask = (1 << GPIO_11_27_IRQ(irq));
+#ifdef CONFIG_RTHAL
+	unsigned long flags;
+
+	hard_save_flags_cli(flags);
+#endif
 	if (GPIO_11_27_spurious & mask) {
 		/*
 		 * We don't want to miss an interrupt that would have occurred
@@ -181,8 +220,17 @@ static void sa1100_unmask_GPIO11_27_irq(
 			/* just in case it gets referenced: */
 			struct pt_regs dummy;
 
+#ifdef CONFIG_RTHAL
+			hard_restore_flags(flags);
+#endif
 			memzero(&dummy, sizeof(dummy));
+#ifndef CONFIG_RTHAL
 			do_IRQ(irq, &dummy);
+#else
+			hard_cli();
+			rthal.c_do_IRQ(irq, &dummy);
+			hard_restore_flags(flags);
+#endif
 
 			/* we are being called recursively from do_IRQ() */
 			return;
@@ -191,8 +239,12 @@ static void sa1100_unmask_GPIO11_27_irq(
 
 	GPIO_IRQ_mask |= mask;
 
-	GRER = GPIO_IRQ_rising_edge & GPIO_IRQ_mask;
-	GFER = GPIO_IRQ_falling_edge & GPIO_IRQ_mask;
+	GRER |= (GPIO_IRQ_rising_edge & mask);
+	GFER |= (GPIO_IRQ_falling_edge & mask);
+	irq_desc[irq].masked = 0;
+#ifdef CONFIG_RTHAL
+	hard_restore_flags(flags);
+#endif
 }
 
 static struct resource irq_resource = {
@@ -235,6 +287,7 @@ void __init sa1100_init_irq(void)
 		irq_desc[irq].mask_ack	= sa1100_mask_and_ack_GPIO0_10_irq;
 		irq_desc[irq].mask	= sa1100_mask_GPIO0_10_irq;
 		irq_desc[irq].unmask	= sa1100_unmask_GPIO0_10_irq;
+		irq_desc[irq].masked	= 0;
 	}
 
 	for (irq = 11; irq <= 31; irq++) {
@@ -243,6 +296,7 @@ void __init sa1100_init_irq(void)
 		irq_desc[irq].mask_ack	= sa1100_mask_irq;
 		irq_desc[irq].mask	= sa1100_mask_irq;
 		irq_desc[irq].unmask	= sa1100_unmask_irq;
+		irq_desc[irq].masked	= 0;
 	}
 
 	for (irq = 32; irq <= 48; irq++) {
@@ -251,6 +305,9 @@ void __init sa1100_init_irq(void)
 		irq_desc[irq].mask_ack	= sa1100_mask_and_ack_GPIO11_27_irq;
 		irq_desc[irq].mask	= sa1100_mask_GPIO11_27_irq;
 		irq_desc[irq].unmask	= sa1100_unmask_GPIO11_27_irq;
+		irq_desc[irq].masked	= 0;
 	}
 	setup_arm_irq( IRQ_GPIO11_27, &GPIO11_27_irq );
 }
+
+EXPORT_SYMBOL(sa1100_GPIO11_27_demux);
diff -urNp linux-2.4.21-rmk1-pxa1/arch/arm/mm/ioremap.c linux-2.4.21-rmk1-pxa1-rthal5/arch/arm/mm/ioremap.c
--- linux-2.4.21-rmk1-pxa1/arch/arm/mm/ioremap.c	Tue Oct  7 19:13:16 2003
+++ linux-2.4.21-rmk1-pxa1-rthal5/arch/arm/mm/ioremap.c	Thu Dec  4 17:17:09 2003
@@ -107,6 +107,9 @@ remap_area_pages(unsigned long address, 
 		if (remap_area_pmd(pmd, address, end - address,
 					 pfn + (address >> PAGE_SHIFT), flags))
 			break;
+#ifdef CONFIG_RTHAL
+		set_pgdir(address, *dir);
+#endif
 		error = 0;
 		address = (address + PGDIR_SIZE) & PGDIR_MASK;
 		dir++;
diff -urNp linux-2.4.21-rmk1-pxa1/arch/arm/mm/proc-sa110.S linux-2.4.21-rmk1-pxa1-rthal5/arch/arm/mm/proc-sa110.S
--- linux-2.4.21-rmk1-pxa1/arch/arm/mm/proc-sa110.S	Tue Oct  7 19:13:16 2003
+++ linux-2.4.21-rmk1-pxa1-rthal5/arch/arm/mm/proc-sa110.S	Thu Dec  4 17:17:09 2003
@@ -86,12 +86,12 @@ Lclean_switch:	.long	0
 	.align	5
 ENTRY(cpu_sa110_data_abort)
 ENTRY(cpu_sa1100_data_abort)
-	mrc	p15, 0, r3, c5, c0, 0		@ get FSR
+	mrc	p15, 0, r1, c5, c0, 0		@ get FSR
 	mrc	p15, 0, r0, c6, c0, 0		@ get FAR
-	ldr	r1, [r2]			@ read aborted instruction
-	and	r3, r3, #255
-	tst	r1, r1, lsr #21			@ C = bit 20
-	sbc	r1, r1, r1			@ r1 = C - 1
+	ldr	r3, [r2]			@ read aborted instruction
+	bic	r1, r1, #1 << 11 | 1 << 10
+	tst	r3, #1 << 20
+	orreq	r1, r1, #1 << 11
 	mov	pc, lr
 
 /*
diff -urNp linux-2.4.21-rmk1-pxa1/include/asm-arm/arch-pxa/irq.h linux-2.4.21-rmk1-pxa1-rthal5/include/asm-arm/arch-pxa/irq.h
--- linux-2.4.21-rmk1-pxa1/include/asm-arm/arch-pxa/irq.h	Thu Dec  4 17:15:17 2003
+++ linux-2.4.21-rmk1-pxa1-rthal5/include/asm-arm/arch-pxa/irq.h	Thu Dec  4 17:17:09 2003
@@ -17,3 +17,6 @@
  * Since it doesn't exist elsewhere, we'll put it here for now.
  */
 extern void do_IRQ(int irq, struct pt_regs *regs);
+#ifdef CONFIG_RTHAL
+extern void pxa_GPIO_2_80_demux(int irq, void *dev_id, struct pt_regs *regs);
+#endif
diff -urNp linux-2.4.21-rmk1-pxa1/include/asm-arm/arch-pxa/time.h linux-2.4.21-rmk1-pxa1-rthal5/include/asm-arm/arch-pxa/time.h
--- linux-2.4.21-rmk1-pxa1/include/asm-arm/arch-pxa/time.h	Thu Dec  4 17:15:17 2003
+++ linux-2.4.21-rmk1-pxa1-rthal5/include/asm-arm/arch-pxa/time.h	Thu Dec  4 17:17:09 2003
@@ -11,6 +11,7 @@
  */
 
 
+#ifndef MODULE
 static inline unsigned long pxa_get_rtc_time(void)
 {
 	return RCNR;
@@ -36,7 +37,11 @@ static unsigned long pxa_gettimeoffset (
 	unsigned long ticks_to_match, elapsed, usec;
 
 	/* Get ticks before next timer match */
+#ifndef CONFIG_RTHAL
 	ticks_to_match = OSMR0 - OSCR;
+#else
+	ticks_to_match = rthal.timer_match - OSCR;
+#endif
 
 	/* We need elapsed ticks since last match */
 	elapsed = LATCH - ticks_to_match;
@@ -46,6 +51,7 @@ static unsigned long pxa_gettimeoffset (
 
 	return usec;
 }
+#endif
 
 static void pxa_timer_interrupt(int irq, void *dev_id, struct pt_regs *regs)
 {
@@ -67,10 +73,14 @@ static void pxa_timer_interrupt(int irq,
 		do_timer(regs);
 		OSSR = OSSR_M0;  /* Clear match on timer 0 */
 		next_match = (OSMR0 += LATCH);
+#ifdef CONFIG_RTHAL
+		rthal.timer_match = next_match;
+#endif
 		restore_flags( flags );
 	} while( (signed long)(next_match - OSCR) <= 0 );
 }
 
+#ifndef MODULE
 extern inline void setup_timer (void)
 {
 	gettimeoffset = pxa_gettimeoffset;
@@ -83,4 +93,4 @@ extern inline void setup_timer (void)
 	OIER |= OIER_E0;	/* enable match on timer 0 to cause interrupts */
 	OSCR = 0;		/* initialize free-running timer, force first match */
 }
-
+#endif
diff -urNp linux-2.4.21-rmk1-pxa1/include/asm-arm/arch-sa1100/irq.h linux-2.4.21-rmk1-pxa1-rthal5/include/asm-arm/arch-sa1100/irq.h
--- linux-2.4.21-rmk1-pxa1/include/asm-arm/arch-sa1100/irq.h	Mon Nov  5 09:21:44 2001
+++ linux-2.4.21-rmk1-pxa1-rthal5/include/asm-arm/arch-sa1100/irq.h	Thu Dec  4 17:17:09 2003
@@ -11,3 +11,6 @@
  * Since it doesn't exist elsewhere, we'll put it here for now.
  */
 extern void do_IRQ(int irq, struct pt_regs *regs);
+#ifdef CONFIG_RTHAL
+extern void sa1100_GPIO11_27_demux(int irq, void *dev_id, struct pt_regs *regs);
+#endif
diff -urNp linux-2.4.21-rmk1-pxa1/include/asm-arm/arch-sa1100/time.h linux-2.4.21-rmk1-pxa1-rthal5/include/asm-arm/arch-sa1100/time.h
--- linux-2.4.21-rmk1-pxa1/include/asm-arm/arch-sa1100/time.h	Tue Oct  7 19:13:27 2003
+++ linux-2.4.21-rmk1-pxa1-rthal5/include/asm-arm/arch-sa1100/time.h	Thu Dec  4 17:17:09 2003
@@ -52,8 +52,11 @@ static unsigned long sa1100_gettimeoffse
 	unsigned long ticks_to_match, elapsed, usec;
 
 	/* Get ticks before next timer match */
+#ifndef CONFIG_RTHAL
 	ticks_to_match = OSMR0 - OSCR;
-
+#else
+	ticks_to_match = rthal.timer_match - OSCR;
+#endif
 	/* We need elapsed ticks since last match */
 	elapsed = LATCH - ticks_to_match;
 
@@ -74,6 +77,9 @@ static void sa1100_timer_interrupt(int i
 		do_timer(regs);
 		OSSR = OSSR_M0;  /* Clear match on timer 0 */
 		next_match = (OSMR0 += LATCH);
+#ifdef CONFIG_RTHAL
+		rthal.timer_match = next_match;
+#endif
 		local_irq_restore(flags);
 		do_set_rtc();
 	} while ((signed long)(next_match - OSCR) <= 0);
diff -urNp linux-2.4.21-rmk1-pxa1/include/asm-arm/atomic.h linux-2.4.21-rmk1-pxa1-rthal5/include/asm-arm/atomic.h
--- linux-2.4.21-rmk1-pxa1/include/asm-arm/atomic.h	Tue Oct  7 19:13:26 2003
+++ linux-2.4.21-rmk1-pxa1-rthal5/include/asm-arm/atomic.h	Thu Dec  4 17:17:09 2003
@@ -27,7 +27,18 @@ typedef struct { volatile int counter; }
 #define ATOMIC_INIT(i)	{ (i) }
 
 #ifdef __KERNEL__
+
+#ifdef CONFIG_RTHAL
+/* RTAI Modification, azu */
+#include <asm/proc/hard_system.h>
+#define _atomic_irq_save(x)	hard_local_irq_save(x)
+#define _atomic_irq_restore(x)	hard_local_irq_restore(x)
+#else
+/* Normal mode */
 #include <asm/proc/system.h>
+#define _atomic_irq_save(x)	local_irq_save(x)
+#define _atomic_irq_restore(x)	local_irq_restore(x)
+#endif
 
 #define atomic_read(v)	((v)->counter)
 #define atomic_set(v,i)	(((v)->counter) = (i))
@@ -36,36 +47,36 @@ static inline void atomic_add(int i, vol
 {
 	unsigned long flags;
 
-	local_irq_save(flags);
+	_atomic_irq_save(flags);
 	v->counter += i;
-	local_irq_restore(flags);
+	_atomic_irq_restore(flags);
 }
 
 static inline void atomic_sub(int i, volatile atomic_t *v)
 {
 	unsigned long flags;
 
-	local_irq_save(flags);
+	_atomic_irq_save(flags);
 	v->counter -= i;
-	local_irq_restore(flags);
+	_atomic_irq_restore(flags);
 }
 
 static inline void atomic_inc(volatile atomic_t *v)
 {
 	unsigned long flags;
 
-	local_irq_save(flags);
+	_atomic_irq_save(flags);
 	v->counter += 1;
-	local_irq_restore(flags);
+	_atomic_irq_restore(flags);
 }
 
 static inline void atomic_dec(volatile atomic_t *v)
 {
 	unsigned long flags;
 
-	local_irq_save(flags);
+	_atomic_irq_save(flags);
 	v->counter -= 1;
-	local_irq_restore(flags);
+	_atomic_irq_restore(flags);
 }
 
 static inline int atomic_dec_and_test(volatile atomic_t *v)
@@ -73,10 +84,10 @@ static inline int atomic_dec_and_test(vo
 	unsigned long flags;
 	int val;
 
-	local_irq_save(flags);
+	_atomic_irq_save(flags);
 	val = v->counter;
 	v->counter = val -= 1;
-	local_irq_restore(flags);
+	_atomic_irq_restore(flags);
 
 	return val == 0;
 }
@@ -86,10 +97,10 @@ static inline int atomic_add_negative(in
 	unsigned long flags;
 	int val;
 
-	local_irq_save(flags);
+	_atomic_irq_save(flags);
 	val = v->counter;
 	v->counter = val += i;
-	local_irq_restore(flags);
+	_atomic_irq_restore(flags);
 
 	return val < 0;
 }
@@ -98,9 +109,9 @@ static inline void atomic_clear_mask(uns
 {
 	unsigned long flags;
 
-	local_irq_save(flags);
+	_atomic_irq_save(flags);
 	*addr &= ~mask;
-	local_irq_restore(flags);
+	_atomic_irq_restore(flags);
 }
 
 /* Atomic operations are already serializing on ARM */
diff -urNp linux-2.4.21-rmk1-pxa1/include/asm-arm/mach/irq.h linux-2.4.21-rmk1-pxa1-rthal5/include/asm-arm/mach/irq.h
--- linux-2.4.21-rmk1-pxa1/include/asm-arm/mach/irq.h	Tue Oct  7 19:13:27 2003
+++ linux-2.4.21-rmk1-pxa1-rthal5/include/asm-arm/mach/irq.h	Thu Dec  4 17:17:09 2003
@@ -18,7 +18,8 @@ struct irqdesc {
 	unsigned int	 probe_ok : 1;		/* IRQ can be used for probe  */
 	unsigned int	 valid    : 1;		/* IRQ claimable	      */
 	unsigned int	 noautoenable : 1;	/* don't automatically enable IRQ */
-	unsigned int	 unused   :25;
+	unsigned int	 masked   : 1;		/* IRQ is masked */
+	unsigned int	 unused   :24;
 	unsigned int	 disable_depth;
 
 	struct list_head pend;
diff -urNp linux-2.4.21-rmk1-pxa1/include/asm-arm/pgalloc.h linux-2.4.21-rmk1-pxa1-rthal5/include/asm-arm/pgalloc.h
--- linux-2.4.21-rmk1-pxa1/include/asm-arm/pgalloc.h	Mon Nov  5 09:21:44 2001
+++ linux-2.4.21-rmk1-pxa1-rthal5/include/asm-arm/pgalloc.h	Thu Dec  4 17:17:09 2003
@@ -138,4 +138,33 @@ static inline pgd_t *pgd_alloc(struct mm
 
 extern int do_check_pgt_cache(int, int);
 
+#ifdef CONFIG_RTHAL
+extern inline void set_pgdir(unsigned long address, pgd_t entry)
+{
+	struct task_struct * p;
+	pgd_t *pgd;
+#ifdef CONFIG_SMP
+	int i;
+#endif
+
+	read_lock(&tasklist_lock);
+	for_each_task(p) {
+		if (!p->mm)
+			continue;
+		*pgd_offset(p->mm,address) = entry;
+	}
+	read_unlock(&tasklist_lock);
+#ifndef CONFIG_SMP
+	for (pgd = (pgd_t *)pgd_quicklist; pgd; pgd = (pgd_t *)__pgd_next(pgd))
+		pgd[pgd_index(address)] = entry;
+#else
+	/* To pgd_alloc/pgd_free, one holds master kernel lock and so does our callee, so we can
+	   modify pgd caches of other CPUs as well. -jj */
+	for (i = 0; i < NR_CPUS; i++)
+		for (pgd = (pgd_t *)cpu_data[i].pgd_quick; pgd; pgd = (pgd_t *)__pgd_next(pgd))
+			pgd[pgd_index(address)] = entry;
+#endif
+}
+#endif /* CONFIG_RTHAL */
+
 #endif
diff -urNp linux-2.4.21-rmk1-pxa1/include/asm-arm/proc-armv/hard_system.h linux-2.4.21-rmk1-pxa1-rthal5/include/asm-arm/proc-armv/hard_system.h
--- linux-2.4.21-rmk1-pxa1/include/asm-arm/proc-armv/hard_system.h	Thu Jan  1 01:00:00 1970
+++ linux-2.4.21-rmk1-pxa1-rthal5/include/asm-arm/proc-armv/hard_system.h	Thu Dec  4 17:17:09 2003
@@ -0,0 +1,136 @@
+/*
+ *  linux/include/asm-arm/proc-armv/hard_system.h
+ *
+ *  Copyright (C) 1996 Russell King
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ */
+
+/*
+ * RTAI
+ * The hard manipulation for enabling/disabling interrupts and related stuff.
+ */
+
+#ifndef __ASM_PROC_HARD_SYSTEM_H
+#define __ASM_PROC_HARD_SYSTEM_H
+
+#include <linux/config.h>
+
+/*
+ * Save the current interrupt enable state & disable IRQs
+ */
+#define hard_local_irq_save(x)					\
+	({							\
+		unsigned long temp;				\
+	__asm__ __volatile__(					\
+	"mrs	%0, cpsr		@ local_irq_save\n"	\
+"	orr	%1, %0, #128\n"					\
+"	msr	cpsr_c, %1"					\
+	: "=r" (x), "=r" (temp)					\
+	:							\
+	: "memory");						\
+	})
+	
+#define hard_local_irq_set(x)					\
+	({							\
+		unsigned long temp;				\
+	__asm__ __volatile__(					\
+	"mrs	%0, cpsr		@ local_irq_set\n"	\
+"	bic	%1, %0, #128\n"					\
+"	msr	cpsr_c, %1"					\
+	: "=r" (x), "=r" (temp)					\
+	:							\
+	: "memory");						\
+	})
+
+/*
+ * Enable IRQs
+ */
+#define hard_local_irq_enable()					\
+	({							\
+		unsigned long temp;				\
+	__asm__ __volatile__(					\
+	"mrs	%0, cpsr		@ local_irq_enable\n"	\
+"	bic	%0, %0, #128\n"					\
+"	msr	cpsr_c, %0"					\
+	: "=r" (temp)						\
+	:							\
+	: "memory");						\
+	})
+
+/*
+ * Disable IRQs
+ */
+#define hard_local_irq_disable()				\
+	({							\
+		unsigned long temp;				\
+	__asm__ __volatile__(					\
+	"mrs	%0, cpsr		@ local_irq_disable\n"	\
+"	orr	%0, %0, #128\n"					\
+"	msr	cpsr_c, %0"					\
+	: "=r" (temp)						\
+	:							\
+	: "memory");						\
+	})
+
+/*
+ * Enable FIQs
+ */
+#define hard_stf()						\
+	({							\
+		unsigned long temp;				\
+	__asm__ __volatile__(					\
+	"mrs	%0, cpsr		@ stf\n"		\
+"	bic	%0, %0, #64\n"					\
+"	msr	cpsr_c, %0"					\
+	: "=r" (temp)						\
+	:							\
+	: "memory");						\
+	})
+
+/*
+ * Disable FIQs
+ */
+#define hard_clf()						\
+	({							\
+		unsigned long temp;				\
+	__asm__ __volatile__(					\
+	"mrs	%0, cpsr		@ clf\n"		\
+"	orr	%0, %0, #64\n"					\
+"	msr	cpsr_c, %0"					\
+	: "=r" (temp)						\
+	:							\
+	: "memory");						\
+	})
+
+/*
+ * Save the current interrupt enable state.
+ */
+#define hard_local_save_flags(x)				\
+	({							\
+	__asm__ __volatile__(					\
+	"mrs	%0, cpsr		@ local_save_flags\n"	\
+	  : "=r" (x)						\
+	  :							\
+	  : "memory");						\
+	})
+
+/*
+ * restore saved IRQ & FIQ state
+ */
+#define hard_local_irq_restore(x)				\
+	__asm__ __volatile__(					\
+	"msr	cpsr_c, %0		@ local_irq_restore\n"	\
+	:							\
+	: "r" (x)						\
+	: "memory")
+
+#define hard_cli() hard_local_irq_disable()
+#define hard_sti() hard_local_irq_enable()
+#define hard_save_flags_cli(x) hard_local_irq_save(x)
+#define hard_restore_flags(x) hard_local_irq_restore(x)
+#define hard_save_flags(x) hard_local_save_flags(x)
+
+#endif
diff -urNp linux-2.4.21-rmk1-pxa1/include/asm-arm/proc-armv/system.h linux-2.4.21-rmk1-pxa1-rthal5/include/asm-arm/proc-armv/system.h
--- linux-2.4.21-rmk1-pxa1/include/asm-arm/proc-armv/system.h	Tue Oct  7 19:13:27 2003
+++ linux-2.4.21-rmk1-pxa1-rthal5/include/asm-arm/proc-armv/system.h	Thu Dec  4 17:17:09 2003
@@ -42,6 +42,38 @@ extern unsigned long cr_alignment;	/* de
 #define vectors_base()	(0)
 #endif
 
+#ifdef CONFIG_RTHAL
+#include <asm/proc/ptrace.h>
+
+/*
+ * RTAI
+ * Definition of rthal.
+ * Do not change this structure unless you know what you are doing!
+ * Filled with values in arch/arm/kernel/irq.c
+ */
+
+struct rt_hal {
+	void (*do_IRQ)(int, struct pt_regs*); /* must be first - arch/arm/kernel/entry-armv.S */
+	long long (*do_SRQ)(int, unsigned long); /* must be second - arch/arm/kernel/entry-common.S */
+	int (*do_TRAP)(int, struct pt_regs*); /* must be third - arch/arm/kernel/entry-armv.S */
+	void (*disint)(void);
+	void (*enint)(void);
+	unsigned int (*getflags)(void);
+	void (*setflags)(unsigned int);
+	unsigned int (*getflags_and_cli)(void);
+	void (*fdisint)(void);
+	void (*fenint)(void);
+	volatile u32 timer_match; /* Soft next Linux timer-interrupt */
+	void (*copy_back)(unsigned long, int);
+	void (*c_do_IRQ)(int, struct pt_regs*);
+	unsigned int (*getflags_and_sti)(void);
+} __attribute__ ((__aligned__ (32)));
+
+volatile extern struct rt_hal rthal;
+
+#endif
+
+#ifndef CONFIG_RTHAL
 /*
  * Save the current interrupt enable state & disable IRQs
  */
@@ -151,6 +183,19 @@ extern unsigned long cr_alignment;	/* de
 	: "r" (x)						\
 	: "memory")
 
+#else
+#define local_irq_save(x)	do { x = rthal.getflags_and_cli(); } while (0)
+#define local_irq_set(x)	do { x = rthal.getflags_and_sti(); } while (0)
+#define local_irq_enable()	do { rthal.enint(); } while (0)
+#define local_irq_disable()	do { rthal.disint(); } while (0)
+#define __stf()			do { rthal.fenint(); } while (0)
+#define __clf()			do { rthal.fdisint(); } while (0)
+#define local_save_flags(x)	do { x = rthal.getflags(); } while (0)
+#define local_irq_restore(x)	do { rthal.setflags(x); } while (0)
+
+#include <asm/proc/hard_system.h>
+#endif	
+
 #if defined(CONFIG_CPU_SA1100) || defined(CONFIG_CPU_SA110)
 /*
  * On the StrongARM, "swp" is terminally broken since it bypasses the
@@ -177,6 +222,7 @@ static inline unsigned long __xchg(unsig
 
 	switch (size) {
 #ifdef swp_is_buggy
+#ifndef CONFIG_RTHAL /* original stuff */
 		case 1:
 			local_irq_save(flags);
 			ret = *(volatile unsigned char *)ptr;
@@ -190,6 +236,21 @@ static inline unsigned long __xchg(unsig
 			*(volatile unsigned long *)ptr = x;
 			local_irq_restore(flags);
 			break;
+#else /* CONFIG_RTHAL keep it atomic */
+		case 1:
+			hard_local_irq_save(flags);
+			ret = *(volatile unsigned char *)ptr;
+			*(volatile unsigned char *)ptr = x;
+			hard_local_irq_restore(flags);
+			break;
+
+		case 4:
+			hard_local_irq_save(flags);
+			ret = *(volatile unsigned long *)ptr;
+			*(volatile unsigned long *)ptr = x;
+			hard_local_irq_restore(flags);
+			break;
+#endif /* CONFIG_RTHAL */
 #else
 		case 1:	__asm__ __volatile__ ("swpb %0, %1, [%2]"
 					: "=&r" (ret)
